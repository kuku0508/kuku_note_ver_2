---
參考資料:
tags:
---
# 第一大題
幾何分配（失敗次數）
- 問是不是指數族
- 充分統計量定義證明充分
- 請用factorization theorem證明充分
- 完備定義證明統計量完備
- 利用指數族 他的$Q(\theta)$ 包含一個非退化的矩形來證明統計量完備
- 寫出最小充分統計量（因為他是完備充分統計量）或用比值
- 用動差法找出動差估計量
- 找出他的MLE
- 問他的MLE是不是最小充分（MLE如果唯一存在且本身具充分性，則為最小充分）
- 找參數函數的MLE（不變性）
- 把參數空間做限制，試問他的MLE（例如原本範圍是$0<\theta<1\Rightarrow 0.5<\theta<1$）
# 第二大題
已知分配（跟p.294 1.11有點像，$\beta=1、\alpha未知$）
- 證明統計量是不是充分統計量（方式隨意）$T(\underline{X})$
- 證明統計量是不是完備統計量（方式隨意）$T(\underline{X})$
- 證明統計量是輔助統計量$U(\underline{X})$
- 問完備統計量跟輔助統計量有沒有獨立（basu's theorem）
# 第三大題
給一個簡單線性迴歸的模式
- 寫出$\beta_0$、$\beta_1$、$\sigma^2$ 的likelihood function
- 寫出$\beta_0$、$\beta_1$、$\sigma^2$ 的MLE
- 證明$\hat{\beta_0}$是$\beta_0$的不偏估計量
- 證明$\hat{\beta_1}$是$\beta_1$的不偏估計量

# 第一大題練習
我們直接拿這個來當作我們練習的分配
$$
f(x;\theta)=\theta(1-\theta)^x,\quad x=0,1,2\ldots,\quad \text{where }0<\theta<1
$$
#### 試問此幾何分配是否為指數族？
當我們要判斷一個分配是不是屬於exponential family的時候，我們需要進行以下的步驟：
	1. 寫出分配的pmf/pdf
	2. 把有包含參數跟隨機變數的部分，改寫成exp的形式
	   $$
	   h(x)c(\theta)exp[T(x)Q(\theta)]
	   $$
	   其中：
	   $h(x)$：與$\theta$無關，可以為常數
	   $c(\theta)$：與$\theta$有關，不包含x
	   $T(x)$：與$\theta$無關，須包含x
	   $Q(\theta)$：與$\theta$有關，不可為常數
那我們開始整理
$$
\begin{align}
f(x;\theta)&=\theta(1-\theta)^x\\
&=\theta\cdot exp\lbrace x\ln(1-\theta) \rbrace\\
&=\underbrace{1}_{h(x)}\cdot\underbrace{\theta}_{c(\theta)}\cdot exp\lbrace\underbrace{x}_{T(x)}\cdot\underbrace{\ln(1-\theta)}_{Q(\theta)}\rbrace
\end{align}
$$
故我們可以知道幾何分配為指數族。

考卷我會直接寫：
$$\begin{align}
f(x;\theta)&=\theta(1-\theta)^x\\
&=\theta\cdot exp\lbrace x\ln(1-\theta) \rbrace\\
&=1\cdot\theta\cdot exp\lbrace x\ln(1-\theta)\rbrace\\
\end{align}
$$
$$
\begin{align}
&\because1\cdot\theta\cdot exp\lbrace x\ln(1-\theta)\rbrace\Rightarrow h(x)c(\theta)exp\lbrace T(x)Q(\theta) \rbrace\\
&\text{where }h(x)=1,\, c(\theta)=\theta,\,T(x)=x,\,Q(\theta)=\ln(1-\theta)\\
&\therefore \text{Hence,the Geometric distribution belong to Exponential family}
\end{align}
$$


#### 請用充分統計量的定義證明
我們需要一個統計量來帶我們接下來的題目，我們這邊先用總和$T=\sum^n_{i=1}x_i$做為題目的統計量。

Hence, the Geometric distribution is belong to exponential family


sufficient statistic 充分統計量
A statistic $T(\underline{X})$ is a sufficient statistic for $\theta$ if the conditional distribution of the sample $\underline{X}$ given the value of $T(\underline{X})$ does not depend on $\theta$ that is $f_{\underline{X}\mid T}(\underline{x}\mid t)$ is independent of $\theta$ .

也就是當在給定$T(\underline{X})=t$ 的前提下，若條件分配
$$
f_{\underline{X}\mid T}(\underline{x}\mid t)
=\frac{P(\underline{X}=x,T(\underline{X})=T(x))}{P(T(\underline{X})=t)}
=\frac{P(X=x)}{P(T(\underline{X})=t)}
=\frac{f_{\underline{X}}(x;\theta)}{f_T(t;\theta)}
$$
若此條件分配不含參數$\theta$，則$T(\underline{X})$為充分統計量。
其中
$f_{\underline{X}}(x;\theta)$為joint pmf/pdf。
$f_T(t;\theta)$為T的pmf/pdf。

Since $X_i$ represents the number of failures before the i-th success, the sum $T=\sum^n_{i=1}X_i$ represents the total number of failures before the n-th success,
hence, $T \sim NegBin(n,\theta)$.

$$
\begin{align}
f_{\underline{X}\mid T}(\underline{x}\mid t)=\frac{f_\underline{X}(x;\theta)}{f_T(t;\theta)}&=\frac{\prod^n_{i=1}\theta(1-\theta)^x}{\binom{n+t-1}{t}\theta^n(1-\theta)^t}\quad(Hence,T\sim NegBin(n,\theta))\\
&=\frac{\theta^n(1-\theta)^{\sum^n_{i=1}x_i}}{\binom{n+t-1}{t}\theta^n(1-\theta)^t}\\
&=\frac{\cancel{\theta^n(1-\theta)^{t}}}{\binom{n+t-1}{t}\cancel{\theta^n(1-\theta)^t}}\\
&=\frac{1}{\binom{n+t-1}{t}}
\end{align}
$$
$\because$ $f_{\underline{X}\mid T}(\underline{x}\mid t)$ is independent of parameter $\theta$
$\therefore$ $T(\underline{X})$ is sufficient statistic for $\theta$.

#### 請用factorization theorem證明充分
**Fisher-Neyman Factorization Theorem**
Let $X_1,\ldots,X_n$ be a random sample from $f(x;\theta)$ , $\theta\in \Omega$ , the statistic $T(\underline{X})$ is sufficient for $\theta$ if and only if the joint pdf of $X_1,\ldots,X_n$ factor as follows.
$$
f(\underline{X};\theta)=g(T(\underline{X}),\theta)h(\underline{X})
$$
where g depends on $X_1,\ldots,X_n$ only through T and h is independent of $\theta$

簡單來說，**我們只要把joint pdf整理成$g(T(\underline{X}),\theta)h(\underline{X})$**，就可以直接說by factorization Theorem，$T(\underline{X})$ is sufficient for $\theta$.
其中
$h(\underline{X})$：不含參數$\theta$的任何東西。
$g(T(\underline{X}),\theta)$：含$T(\underline{X})$，可以含$\theta$，可以是常數。

$$
\begin{align}
f(\underline{x};\theta)&=\prod^n_{i=1}\theta(1-\theta)^{x_i}\\
&=\theta^n(1-\theta)^{\sum^n_{i=1}x_i}\\
&=\theta^n(1-\theta)^T
\end{align}
$$
$\because$ where $h(\underline{x})=1$ and $g(T(\underline{X}),\theta)=\theta^n(1-\theta)^T$  。
$\therefore$ By factorization theorem, $T(\underline{X})$ is sufficient statistic.
#### 使用完備定義證明統計量完備
要證明一個分配完備，我們可以找到一個函數$g(x)$，
這個函數會使分配的參數不管為何，他的期望值都是0
也就是$E(g(x))=0$ ,$\forall \theta$。
而我們只要證明只有當g(x)為0函數的情況下，才可能發生上面那個情況。
我們就等於證明了這個分配族完備。

Let g be a function such that $E[g(t)]=0\quad for \,\,0<\theta<1$ 
$$
\begin{align}
E[g(t)]&=\sum^\infty_{t=0}g(t)\binom{n+t-1}{t}\cdot\theta^n(1-\theta)^t\\
&\because \theta^n>0\\
&=\sum^\infty_{t=0}{g(t)\binom{n+t-1}{t}}(1-\theta)^t\\
&\because \sum^\infty_{i=0} a_i\cdot x^i= a_0+a_1\cdot x+a_2\cdot x^2+a_3\cdot x^3+\ldots=0\\
&\Rightarrow a_i=0\quad\text{where }a_i=g(t)\binom{n+t-1}{t}\,and \,x=(1-\theta)\\
&\therefore g(t)\binom{n+t-1}{t}=0\\
&\because \binom{n+t-1}{t}>0\\
&\therefore g(t)=0
\end{align}
$$
Since $E[g(t)]=0$ if and only if $g(t)=0$
Hence, $T(\underline{X})$ is a complete statistic for $\theta$.

#### 利用指數族 他的$Q(\theta)$ 包含一個非退化的矩形來證明統計量完備
$$
\begin{align}
&Q(\theta)=\ln(1-\theta)\\
&\because 0<\theta<1\\
&\therefore \lim_{\theta\rightarrow 0^+}\ln(1-\theta)=0\\
&\quad\lim_{\theta\rightarrow1^-}\ln(1-\theta)=-\infty\\
&\Rightarrow-\infty<Q(\theta)<0\quad(\text{non-degenerate})
\end{align}
$$
It contain a open interval.

Since the Geometric distribution belongs to a one-parameter exponential family, and the natural parameter space is $Q(\theta)\in(-\infty,0)$
Hence, $T(\underline{X})$ is a complete statistic for $\theta$.

#### 證明統計量為最小充分統計量
Since $T(\underline{X})$ is sufficient and complete for $\theta$ ,
and A complete sufficient statistic is always minimal sufficient.
Hence, $T(\underline{X})$ is minimal sufficient statistic.

#### 用動差法找出動差估計量
$$
\begin{align}
\bar{X}&=E[X]\\
\bar{X}&=\frac{1-\theta}{\theta}\\
\bar{X}\theta&=1-\theta\\
\bar{X}\theta+\theta&=1\\
(\bar{X}+1)\theta&=1\\
\hat{\theta}&=\frac{1}{\bar{X}+1}
\end{align}
$$
#### 找到MLE
1. 先算likelihood：
$$
\begin{align}
L(\theta)&=\prod^n_{i=1}\theta(1-\theta)^{x_i}\\
&=\theta^n(1-\theta)^{\sum^n_{i=1}x_i}\\
\end{align}
$$
2. 對likelihood取ln後微分
$$
\begin{align}
\frac{d}{d\theta}\ln L(\theta)&=\frac{d}{d\theta}\ln[\theta^n(1-\theta)^{\sum^n_{i=1} x_i}]\\
&=\frac{d}{d\theta}\left[\ln\theta^n+\ln(1-\theta)^{\sum^n_{i=1}x_i}\right]\\
&=\frac{d}{d\theta}(n\ln\theta)+\frac{d}{d\theta}\left[\sum^n_{i=1}x_i\ln(1-\theta)\right]\\
&=n\frac{1}{\theta}+\sum^n_{i=1}x_i\frac{d}{d\theta}\left[\ln(1-\theta)\right]\\
&=n\frac{1}{\theta}+\sum^n_{i=1}x_i\frac{d}{du}\left[\ln u\right]\frac{du}{d\theta}\\
&=n\frac{1}{\theta}+\sum^n_{i=1}x_i\cdot\frac{1}{u}\frac{du}{d\theta}\\
&=n\frac{1}{\theta}+\sum^n_{i=1}x_i\cdot\frac{1}{u}\cdot(-1)\\
&=\frac{n}{\theta}-\frac{\sum^n_{i=1}x_i}{u}\\
&=\frac{n}{\theta}-\frac{\sum^n_{i=1}x_i}{1-\theta}\\
\end{align}
$$
3. 將其設為0（為了找最大值）解$\theta$
$$
\begin{align}
&\frac{n}{\theta}-\frac{\sum^n_{i=1}x_i}{1-\theta}=0\\
&\frac{n}{\theta}=\frac{\sum^n_{i=1}x_i}{1-\theta}\\
&\theta\cdot\sum^n_{i=1}x_i=n-n\theta\\
&\theta\cdot\left(\sum^n_{i=1}x_i+n\right)=n\\
&\hat{\theta}=\frac{n}{\sum^n_{i=1}x_i+n}\\
&\because\bar{X}=\frac1n\sum^n_{i=1}x_i\Rightarrow\sum^n_{i=1}x_i=n\bar{X}\\
&\therefore\hat{\theta}=\frac{n}{n\bar{X}+n}\\
&\quad\hat{\theta}=\frac{n}{n\bar{X}+n}\\
&\quad\hat{\theta}=\frac{\cancel{n}}{\cancel{n}(\bar{X}+1)}\\
&\quad\hat{\theta}=\frac{1}{\bar{X}+1}
\end{align}
$$
Hence,$\hat{\theta}$ is MLE of $\theta$
#### 問他的MLE是不是最小充分
Since log-likelihood function has unique maximizer, therefore MLE exists uniquly.
and $\hat{\theta}$ 
#### 找參數函數的MLE（不變性）
##### $\hat{\theta}^2$
By invariance property of MLE,
$$
\hat{\theta^2}=\hat{\theta}^2=\left(\frac{1}{\bar{X}+1}\right)^2
$$
#### $\frac{1-\theta}{\theta}$
By invariance property of MLE
$$
\begin{align}
\widehat{\left(\frac{1-\theta}{\theta}\right)}&=\frac{1-\frac{1}{\bar{X}+1}}{\frac{1}{\bar{X}+1}}\\
&=\frac{1}{\frac{1}{\bar{X}+1}}-\frac{\frac{1}{\bar{X}+1}}{\frac{1}{\bar{X}+1}}\\
&=\bar{X}+1-1\\
&=\bar{X}
\end{align}
$$
$\theta(1-\theta)$
By invariance property of MLE
$$
\begin{align}
\hat{[\theta(1-\theta)]}&=[\hat{\theta}(1-\hat{\theta})]\\
&=\frac{1}{\bar{X}+1}\left(1-\frac{1}{\bar{X}+1}\right)\\
&=
\end{align}
$$