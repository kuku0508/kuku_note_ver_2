##### 前言(碎碎念)：
好煩...感覺這篇筆記就會很長。提醒一下，頭上有^的符號，是指符號的估計值。
- - -
最小平方法（Method of Least Squares），這個是一種估計出簡單線性迴歸的參數的方法。為了瞭解反應變數以及預測變數之間的關係，可以使用散佈圖來檢測模式。當該模式近似呈現為一條直線時，我們關注的是找到配適直線。

而最小平方法就是一種獲得配適直線的方法，該線也被稱為「最小平方直線」、「迴歸線」，最小平方法是通過最小化「觀測值與配適直線之間距離的平方和」來實現的。
- - -
# 推導：
首先我們知道了最小平方法是透過最小化觀測值與配適直線之間距離的平方和來實現的。
而我們知道簡單線性迴歸的公式是$y_i=\beta_0+\beta_1x_i+\epsilon$，而所謂的「觀測值與配適直線之間的距離」就是所謂的$\epsilon$。故我們可以得出這樣的式子：
$$
\begin{align}
\epsilon&=y_i-\beta_0+\beta_1x_i\\
\text{minimize}\,Q&=\sum^n_{i=1}(y_i-\beta_0+\beta_1x_i)^2
\end{align}
$$

而我們可以透過求偏導數的方式來求$\beta_0$、$\beta_1$的公式：
$$
\left.\frac{\partial\,Q}{\partial\,\beta{_0}}\right|_{\hat{\beta_0}\,,\,\hat{\beta_1}}=-2\sum^n_{i=1}(y_i-\hat{\beta_0}-\hat{\beta_1}x_i)=0
$$
$$
\left.\frac{\partial\,Q}{\partial\,\beta{_1}}\right|_{\hat{\beta_0}\,,\,\hat{\beta_1}}=-2\sum^n_{i=1}(y_i-\hat{\beta_0}-\hat{\beta_1}x_i)x_i=0
$$
$\hat{\beta_0}$=$\beta_0$的最小平方估計值
$\hat{\beta_1}$=$\beta_1$的最小平方估計值


而上面兩式經過改寫之後，可以被重寫為最小平方正規方程式：
$$
\begin{align}
n\hat{\beta_0}+\hat{\beta_1}\sum^n_{i=1}x_i=\sum^n_{i=1}y_i
\end{align}
$$

$$
\begin{align}
\hat{\beta_0}\sum^n_{i=1}x_i+\hat{\beta_1}\sum^n_{i=1}x_i^2=\sum^n_{i=1}x_i\,y_i
\end{align}
$$
透過解上面的聯立方程式可以得出以下：
$$
\hat{\beta_0}=\bar{y}-\hat{\beta_1}\bar{x}
$$

$$
\begin{align}
\hat{\beta_1}=\frac{\sum^n_{i=1}(x_i-\bar{x})(y_i-\bar{y})}{\sum^n_{i=1}(x_i-\bar{x})^2}
=\frac{\sum^n_{i=1}(x_i-\bar{x})y_i-\sum^n_{i=1}(x_i-\bar{x})\bar{y}}{\sum^n_{i=1}(x_i-\bar{x})^2}\\\\=
\frac{\sum^n_{i=1}(x_i-\bar{x})y_i-\bar{y}\times\cancel{\sum^n_{i=1}(x_i-\bar{x})}{\sum^n_{i=1}(x_i-\bar{x})^2}=\frac{\sum^n_{i=1}(x_i-\bar{x})y_i}{\sum^n_{i=1}(x_i-\bar{x})^2}
=\frac{S_{xy}}{S_{xx}}
\end{align}
$$
- - -
# 性質：
- $\hat{\beta_0}$跟$\hat{\beta_1}$是$y_i$的<font color=ffb3c6>線性組合</font>
- $E(\hat{\beta_0})=\beta_0$、$E(\hat{\beta_1})=\beta_1$
- $Var(\hat{\beta_0})=\sigma^2(\frac{1}{n}+\frac{\bar{x}^2}{\sum^n_{i=1}(x_i-\bar{x})^2})$、$Var(\hat{\beta_1})=\frac{\sigma^2}{\sum^n_{i=1}(x_i-\bar{x})^2}$
- $Cov(\bar{y},\hat{\beta_1})=0$
- 根據<font color=ffb3c6>高斯-馬可夫定理（Gauss Markov Theorem）</font>在$E(\epsilon)=0$、$Var(\epsilon)=\sigma^2$且誤差不相關的假設下，最小平方估計量$\hat{\beta_0}$和$\hat{\beta_1}$是無偏的(unbiased)，並且在所有無偏線性估計量中具有最小的方差（即為BLUE，best linear unbiased estimator，最佳線性無偏估計量）。
- 回歸線一定會通過($x_i,y_i$)
#### 殘差性質：
- $\sum^n_{i=1}e_i=0$
- $\sum^n_{i=1}y_i=\sum^n_{i=1}\hat{y}_i$
- $\sum^n_{i=1}x_ie_i-0$
- $\sum^n_{i=1}\hat{y_i}e_i=0$
- - -
parent::[[簡單線性迴歸]]